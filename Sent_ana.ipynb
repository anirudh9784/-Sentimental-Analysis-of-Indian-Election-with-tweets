{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sent ana.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-tgaedgXUES",
        "colab_type": "code",
        "outputId": "b66b8776-a902-4038-ea82-aa08f02ec212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import nltk\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from keras.utils import to_categorical\n",
        "import random\n",
        "from tensorflow import set_random_seed\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#set random seed for the session and also for tensorflow that runs in background for keras\n",
        "set_random_seed(123)\n",
        "random.seed(123)\n",
        "train= pd.read_csv(\"gdrive/My Drive/train.csv\")\n",
        "test = pd.read_csv(\"gdrive/My Drive/test_data.csv\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXwnSxETZIoi",
        "colab_type": "code",
        "outputId": "4b26b0a8-bed9-442f-9020-67cd55845c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "train.head()\n",
        "train.shape\n",
        "def clean_sentences(df):\n",
        "    reviews = []\n",
        "\n",
        "    for sent in tqdm(df['text']):\n",
        "        \n",
        "        #remove html content\n",
        "        review_text = BeautifulSoup(sent).get_text()\n",
        "        \n",
        "        #remove non-alphabetic characters\n",
        "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
        "    \n",
        "        #tokenize the sentences\n",
        "        words = word_tokenize(review_text.lower())\n",
        "    \n",
        "        #lemmatize each word to its lemma\n",
        "        lemma_words = [lemmatizer.lemmatize(i) for i in words]\n",
        "    \n",
        "        reviews.append(lemma_words)\n",
        "\n",
        "    return(reviews)\n",
        "\n",
        "#cleaned reviews for both train and test set retrieved\n",
        "train_sentences = clean_sentences(train)\n",
        "test_sentences = clean_sentences(test)\n",
        "print(len(train_sentences))\n",
        "print(len(test_sentences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 400000/400000 [08:15<00:00, 807.04it/s]\n",
            "100%|██████████| 100000/100000 [02:05<00:00, 799.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "400000\n",
            "100000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl5703P5ZVFK",
        "colab_type": "code",
        "outputId": "093e6131-20a1-41c9-ba47-8ad17dd595fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "train= pd.read_csv(\"gdrive/My Drive/train.csv\")\n",
        "train = train.drop(273514,axis=0)\n",
        "train['label'] = pd.to_numeric(train.label, errors='coerce')\n",
        "test = pd.read_csv(\"gdrive/My Drive/test_data.csv\")\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Great mobile app with nice reward program. Mak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Really fast and polite. Definitely recommend. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>This place is always amazing, friendly staff a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>We did a Wine 101 class on a Friday night. Coo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>I am rounding up because I think this place ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                               text\n",
              "0      1  Great mobile app with nice reward program. Mak...\n",
              "1      2  Really fast and polite. Definitely recommend. ...\n",
              "2      2  This place is always amazing, friendly staff a...\n",
              "3      1  We did a Wine 101 class on a Friday night. Coo...\n",
              "4      1  I am rounding up because I think this place ma..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krphxNw8XAXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxMkpUDiVhE6",
        "colab_type": "code",
        "outputId": "dbbdbffc-4ecc-48ce-a7e3-4451d5263f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "target=train.label.values\n",
        "y_target=to_categorical(target)\n",
        "num_classes=y_target.shape[1]\n",
        "X_train,X_val,y_train,y_val=train_test_split(train_sentences,y_target,test_size=0.2,stratify=y_target)\n",
        " #It is needed for initializing tokenizer of keras and subsequent padding\n",
        "\n",
        "unique_words = set()\n",
        "len_max = 0\n",
        "\n",
        "for sent in tqdm(X_train):\n",
        "    \n",
        "    unique_words.update(sent)\n",
        "    \n",
        "    if(len_max<len(sent)):\n",
        "        len_max = len(sent)\n",
        "        \n",
        "#length of the list of unique_words gives the no of unique words\n",
        "print(len(list(unique_words)))\n",
        "print(len_max)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 320000/320000 [00:02<00:00, 115808.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "139494\n",
            "1029\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6V4r6GHVmCD",
        "colab_type": "code",
        "outputId": "8d20cff0-d33b-4801-ec7d-404d0e0ffe82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=len(list(unique_words)))\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "#padding done to equalize the lengths of all input reviews. LSTM networks needs all inputs to be same length.\n",
        "#Therefore reviews lesser than max length will be made equal using extra zeros at end. This is padding.\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=len_max)\n",
        "X_val = sequence.pad_sequences(X_val, maxlen=len_max)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=len_max)\n",
        "print(X_train.shape,X_val.shape,X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(320000, 1029) (80000, 1029) (100000, 1029)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThND0lACVoAo",
        "colab_type": "code",
        "outputId": "93147235-7292-4dd4-c86e-542551394410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "early_stopping = EarlyStopping(min_delta = 0.001, mode = 'max', monitor='val_acc', patience = 2)\n",
        "callback = [early_stopping]\n",
        "\n",
        "#Model using Keras LSTM\n",
        "model=Sequential()\n",
        "model.add(Embedding(len(list(unique_words)),300,input_length=len_max))\n",
        "model.add(LSTM(128,dropout=0.5, recurrent_dropout=0.5,return_sequences=True))\n",
        "model.add(LSTM(64,dropout=0.5, recurrent_dropout=0.5,return_sequences=False))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.005),metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 08:43:09.904083 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0619 08:43:09.928479 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0619 08:43:09.931909 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0619 08:43:10.037517 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0619 08:43:10.047717 139628863997824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0619 08:43:10.684892 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0619 08:43:10.694514 139628863997824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1029, 300)         41848200  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1029, 128)         219648    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               6500      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 42,124,059\n",
            "Trainable params: 42,124,059\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5F-7iGrVp49",
        "colab_type": "code",
        "outputId": "f41abe1b-10de-4332-b27e-65e14483a20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#This is done for learning purpose only. One can play around with different hyper parameters combinations\n",
        "#and try increase the accuracy even more. For example, a different learning rate, an extra dense layer \n",
        "# before output layer, etc. Cross validation could be used to evaluate the model and grid search \n",
        "# further to find unique combination of parameters that give maximum accuracy. This model has a validation\n",
        "#accuracy of around 66.5%\n",
        "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=1, batch_size=180, verbose=1, callbacks=callback)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 08:43:10.834344 139628863997824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 320000 samples, validate on 80000 samples\n",
            "Epoch 1/1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgoc61p4XV3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_downloaded = drive.CreateFile({'id': '1Qtn7zg3nJyHBxK9W4_UQ4n3YE8wZCanM'})\n",
        "train_downloaded.GetContentFile('train.csv')\n",
        "test_downloaded = drive.CreateFile({'id': '1Qtn7zg3nJyHBxK9W4_UQ4n3YE8wZCanM'})\n",
        "test_downloaded.GetContentFile('test.csv')\n",
        "sample_downloaded = drive.CreateFile({'id': '11qHE-xKXeeG1otqjm7nS25N2iGAzSUmy'})\n",
        "sample_downloaded.GetContentFile('sampleTrain.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djsBWxkwXt8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tick = time.time()\n",
        "df = pd.read_csv(\"train.csv\", dtype={\"label\": object, \"text\": object})\n",
        "y = df.label \n",
        "text = df.text\n",
        "\n",
        "print(df.head())\n",
        "#Convert all text to lower case\n",
        "text = text.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
        "\n",
        "#Remove all punctuation\n",
        "for i in range(0, len(text)):\n",
        "    text[i] = re.sub(r'[^\\w\\s]', \"\", text[i])\n",
        "    \n",
        "#for index,row in df.iterrows():\n",
        "#    if df.iloc[index]['text'] == 'My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done!':\n",
        "#        df.drop(index, inplace=True)\n",
        "\n",
        "#Remove stop words (removes important words! needs modification)\n",
        "stop = stopwords.words(\"english\")\n",
        "stop = stop[:143]\n",
        "stop.remove(\"not\")\n",
        "stop.remove(\"against\")\n",
        "stop.remove(\"no\")\n",
        "stop.append(\"My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done! \")\n",
        "text = text.apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
        "\n",
        "#Lemmatize (not working)\n",
        "#text = text.apply(lambda x: \" \".join(Word(x).lemmatize() for x in x.split()))\n",
        "\n",
        "#Stemming\n",
        "\n",
        "#text.drop(\"My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done! \")\n",
        "#seperating words into lists\n",
        "for i, line in enumerate(text):\n",
        "    text[i] = line.split()\n",
        "#print(text)\n",
        "#df.text = text\n",
        "#text = list(text)\n",
        "print(time.time() - tick)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYYp_XmggjPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9nMAB3lith6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.apply(pd.to_numeric, args=('coerce',))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyREVrtGXyM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = text\n",
        "\n",
        "Y = df['label']\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU7NXmIDXyPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RNjAvIhXyRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "#tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer = Tokenizer(num_words=max_features, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n ', lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG5F9SXIX2Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tokenizer.texts_to_sequences(text)\n",
        "X = pad_sequences(X)\n",
        "\n",
        "\n",
        "Y = pd.get_dummies(y.values)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(y.values)\n",
        "print(Y_train.values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03w4abGtX2K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "maxlen = 100\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkEh-S2qeKCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcjtePXrX2NQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,Y_train, Y_test = train_test_split(X,Y, test_size = 0.2)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n",
        "print(y.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWTwR20Vqsm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train=Y_train.drop('My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done!',axis = 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUna14UAtsup",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Y_test.reshape(-1,1)\n",
        "X_test.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCVwnuufX6bN",
        "colab_type": "code",
        "outputId": "097d9f71-adbc-4278-fd19-6475cb417ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "\n",
        "maxlen=571\n",
        "inp = Input(shape=(maxlen, ))\n",
        "embed_size = 300\n",
        "#x = Sequential()\n",
        "x = Embedding(max_features, embed_size)(inp)\n",
        "x = LSTM(300, return_sequences=True,name='lstm_layer')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(256, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(64, activation=\"softmax\")(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 571)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 571, 300)          6000000   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 571, 300)          721200    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_3 (Glob (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               77056     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                8256      \n",
            "=================================================================\n",
            "Total params: 6,839,408\n",
            "Trainable params: 6,839,408\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hSFXYGZX6dM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"start fitting...\")\n",
        "model.fit(X_train, Y_train ,validation_data=(X_test,Y_test), epochs=2,verbose=1, batch_size=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH8uMNM7X8o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = model.evaluate(X_te, y_test)\n",
        "print(\"\\n%s: %.4f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "y_pred = model.predict(X_te, batch_size=8000)\n",
        "y_classes = y_pred.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlzDRItlX8rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z=np.array(y_test)\n",
        "d=y_test.astype(int)\n",
        "d\n",
        "z=np.array(d)\n",
        "z[0]\n",
        "Y_TEST=z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3wDRWUUX8s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "accScore = metrics.accuracy_score(Y_TEST,y_classes)\n",
        "\n",
        "lbl = [0,1,2]\n",
        "precision = metrics.precision_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "recall = metrics.recall_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "f1Score = metrics.f1_score(Y_TEST,y_classes,average=None,labels=lbl)\n",
        "\n",
        "print(\"\\nOverall Acurracy: \",accScore,\"\\n\")\n",
        "\n",
        "for i in range(len(lbl)):\n",
        "    print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
        "    print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
        "    print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]),\"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efLTH6YwX8un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2H1MBevYCjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding, Flatten\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "kernel_size=3\n",
        "embedding_matrix = np.random.randn(20000, 128) * 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnNHgGuVYClq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = Input(shape=(100, ))\n",
        "embed_size = 128\n",
        "x = Embedding(20000,128,weights=[embedding_matrix])(inp)#input_length=maxlen)(inp)\n",
        "x=(Dropout(0.4))(x)\n",
        "x=(Conv1D(600, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(300, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(150, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Conv1D(75, kernel_size, padding='valid', activation='relu', strides=1))(x)\n",
        "x=(Flatten())(x)\n",
        "x=(Dense(600))(x)\n",
        "x=(Dropout(0.5))(x)\n",
        "x=(Activation('relu'))(x)\n",
        "x=(Dense(1))(x)\n",
        "x=(Activation('softmax'))(x)\n",
        "model=Model(inputs=inp, outputs=x)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XLshdDVYCnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-TOCM4SYCpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kaggle competitions submit -c sent -f submission.csv -m \"Message\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcT0WuzOnPvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}